\documentclass[10pt]{article}
\usepackage{amscd,amsfonts,amssymb,amstext,latexsym} 
\usepackage{amsmath,mathbbol,mathrsfs,stmaryrd, mathtools} 

%\usepackage{mathbbol,mathrsfs,stmaryrd}
\usepackage {algorithm} 
\usepackage{theoremref}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} 
\usepackage {enumerate}
\usepackage{url}
\usepackage[noend]{algpseudocode}
\usepackage{float}
\usepackage{graphics} 
\usepackage{tikz}
\usepackage[width=14.8cm,left=3cm]{geometry}
\usetikzlibrary{automata,calc}
%\usepackage{tgtermes} 
\usepackage{listings}
\usepackage{mathptmx}
\usepackage{fancyhdr}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{fancyhdr}
\usepackage{multirow,multicol}
\usepackage{color}
\usepackage[toc,page]{appendix}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}


\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{tabto}
\lstset{ %
language=C,                % choose the language of the code
basicstyle={\ttfamily},       % the size of the fonts that are used for the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
aboveskip=6mm, 
%belowskip=3mm, 
numbers=left, numberfirstline=false, numberblanklines=false,
numberstyle=\tiny\color{gray}, numbersep= 5pt, 
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,           % adds a frame around the code
%frame = tb, 
frame = none, 
tabsize=2,          % sets default tabsize to 2 spaces
captionpos=b,           % sets the caption-position to bottom
breaklines=true,        % sets automatic line breaking
breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}          % if you want to add a comment within your code
}
%\graphicspath{{../../pics/}}
\fancypagestyle{plain}{
\fancyhf{}
\rhead{School of Computer Science and Applied Mathematics\\ 
%\noindent\rule{15.4cm}{0.4pt}\\
\footnotesize{\textsc{University of the Witwatersrand, Johannesburg}}}
\lhead{\includegraphics[scale=0.08]{witslogo_h.png}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
}

\textwidth=16.8cm 
\textheight=22.6cm 
\evensidemargin 0pt 
\oddsidemargin 0pt 
\leftmargin 0pt 
\rightmargin 0pt 
\setlength{\topmargin}{0pt} 
\setlength{\footskip}{50pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}
\linespread{1} 
% 
\makeatletter
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother

%Custom commands for logical operators and other pseudocode stuff
\algnewcommand\AND{\textbf{ and }}
\algnewcommand\OR{\textbf{ or }}
\algnewcommand\NOT{\textbf{not}}
\algnewcommand\BREAK{\textbf{break}}
\algnewcommand\RETURN{\textbf{return }}

\begin{document}
\title{COMS4040A Assignment 1 -- Report}
\author{Tamlin Love\\1438243\\BSc Hons}
\date{\today} 

\maketitle 
%\thispagestyle{empty}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\fancyhead[L]{COMS4040A Assignment 1}
%\vskip 3mm 
%\pagenumbering{roman}
%\newpage
\pagenumbering{arabic} 
\section{Introduction}\label{Introduction}
The k nearest neighbour (KNN) algorithm is a simple, widely used algorithm in used for classification and regression problems\cite{altman92}. Its applications vary from detecting intrusive programs\cite{liao02} to text classification \cite{kwon03} to the analysis of nuclear magnetic resonance spectra \cite{kowalski72}.
\\
The algorithm itself is very simple. Consider a set $P$ of $m$ reference points $p_{i}\in\mathbb{R}^{d}$ and a set $Q$ of $n$ query points $q_{j} \in \mathbb{R}^{d}$. The aim of the algorithm is to find the $k$ nearest (according to some distance measure) points in $P$ for each $q_{j}\in Q$, for some integer $k$. In the brute force approach, the algorithm proceeds as in \ref{alg:kNN} in Appendix \ref{app:Algorithms}.
\\
In essence, we first compute the distance between each query point and each reference point and store it in a distance matrix of size $n \times m$. We then sort each row in the matrix before returning the $n \times k$ (keeping track of any swaps via the index matrix), before returning the $n \times k$ index sub-matrix containing the indices of the k-nearest neighbours to each query point.
\\
Special attention must be given to the distance measure and sorting functions applied above. In this report, we consider the Euclidean distance measure (Algorithm \ref{alg:euclid}) and the Manhattan distance measure (Algorithm \ref{alg:manhattan}), and for sorting we consider the quicksort (Algorithm \ref{alg:qsort}), bubblesort (Algorithm \ref{alg:bubblesort}) and mergesort (Algorithm \ref{alg:mergesort}) algorithms.
\\
Because any distance measure in $\mathbb{R}^{d}$ must take $\mathcal{O}(d)$ time to compute, algorithm \ref{alg:kNN} above must take $\mathcal{O}(mnd)$ time to compute distances. Since quicksort and mergesort are both $\mathcal{O}(mlog(m))$ on average, and bubblesort is $\mathcal{O}(m^2)$ on average, the final algorithm must take $\mathcal{O}(nmlog(m))$ time to sort using quicksort or mergesort, and $\mathcal{O}(nm^2)$ time to sort using bubblesort. For large $m$, $n$ and $d$, these complexities are problematic. However, as we shall see in Section \ref{Methodology}, this can be significantly improved upon using parallel algorithms.
\section{Methodology}\label{Methodology}
As mentioned in Section \ref{Introduction}, there are two computationally intensive sections in Algorithm \ref{alg:kNN}: the distance computation and the sorting component. We shall apply Foster's Design Methodology to each of these sections individually in the hope of improving the performance of the algorithm.
\subsection{Distance Computation}
Consider the two distance measures (Algorithms \ref{alg:euclid}) and \ref{alg:manhattan}). Because the only difference between these algorithms is the square of the difference in Algorithm \ref{alg:euclid} and the absolute value of the difference in Algorithm \ref{alg:manhattan}, they can be dealt with in the same way. No matter the algorithm used, the distance function is performed $nm$ times in lines 4-6 in Algorithm \ref{alg:kNN}. Furthermore, the computation of the distance between points $q_{i}$ and $p_{j}$ is in no way dependent on the computation of distance between points $q_{s}$ and $p_{t}$ for $s\neq i$ and $t\neq j$. We will collapse the for-loops in Algorithm \ref{alg:kNN} into $nm$ tasks which can be divided among processors. 
\\
In practice, this partitioning is done by the OpenMP \textbf{for} directive with the \textbf{collapse(2)} clause. The communication, agglomeration and mapping steps are performed by the OpenMP compiler.
\subsection{Sorting}
Consider the sorting algorithms (Algorithms \ref{alg:qsort}, \ref{alg:bubblesort} and \ref{alg:mergesort}). These are all applied in lines 8-9 of Algorithm \ref{alg:kNN}, which are repeated $n$ times. Here, rather than focus on the loop in Algorithm \ref{alg:kNN}, we will focus on applying Foster's Design Methodology to each sorting algorithm individually.
\subsubsection{Quicksort}
Here we note that each call to Quicksort recursively calls Quicksort on two portions of the list. We can therefore partition each recursive call into a separate task to be executed by a thread. This is done using the OpenMP \textbf{sections}/\textbf{section} construct. However, at a certain point, the overhead involved with scheduling threads becomes significant, so that sorting a small sublist in serial is actually faster than further partitioning the task. We therefore introduce a condition: if $high-low<c$ for some cut-off $c$, we will sort in serial. Otherwise, we will partition further. Communication, agglomeration and mapping is then handled by the OpenMP compiler.
\subsubsection{Mergesort}
Here we note that Mergesort, like Quicksort, recursively calls Mergesort on two portions of the list. Therefore, we can parallelisze it identically: by partitioning each recursive call into a separate task using the OpenMP \textbf{sections}/\textbf{section} construct. Once again, we employ the cut-off condition to reduce overhead.
\subsubsection{Bubblesort}
Here we employ an algorithm known as the Odd-Even sort or the Parallel-Neighbour sort \cite{habermann72}, which essentially sorts pairs of numbers in the list in parallel. These pairs alternate from 0-1, 2-3, 4-5, etc. (even) to 1-2, 3-4, 5-6, etc. (odd). The algorithm, which can be thought of as the parallel version of the bubblesort, is listed as Algorithm \ref{alg:oddeven} in Appendix \ref{app:Algorithms}.
\\
In this algorithm we partition each inner for-loop (lines 4-7) into a task using the OpenMP \textbf{for} directive. Once again, communication, agglomeration and mapping are handled by the OpenMP compiler.
\section{Empirical Analysis}
We begin this section with a description of the hardware upon which the experiments below will be run. We will then discuss the precise implementation of the aforementioned algorithms and finally we detail the experiments themselves.
\section{Summary}
\bibliographystyle{IEEEannot}
\bibliography{myBib}
\begin{appendices}
\section{Algorithms}\label{app:Algorithms}
\begin{algorithm}[H]
\caption{k Nearest Neighbour}\label{alg:kNN}
\begin{algorithmic}[1]
\Procedure{kNN}{P,Q,k}
	\State distance $\gets [][]$
	\State index $\gets [][]$
	\For{$q_{i}\in Q$}
		\For{$p_{j} \in P$}
			\State distance[$i$][$j$] $\gets$ dist($q_{i},p_{j}$)
			\State index[$i$][$j$] $\gets j$
		\EndFor
	\EndFor
	
	\For{each $i$ in distance[$i$]}
		\State sort(distance[$i$],index[$i$])
	\EndFor
	
	\State \RETURN index[$i$][$0:k-1$]
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{appendices}
\begin{algorithm}[H]
\caption{Euclidean Distance}\label{alg:euclid}
\begin{algorithmic}[1]
\Procedure{dist}{$q,p$}
	\State $distance \gets 0$
	\For{$i \in [1,2,...,d]$}
		\State $distance \gets distance + (p_{i} - q_{i})^2$
	\EndFor
	\State \RETURN $\sqrt{distance}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{Manhattan Distance}\label{alg:manhattan}
\begin{algorithmic}[1]
\Procedure{dist}{$q,p$}
	\State $distance \gets 0$
	\For{$i \in [1,2,...,d]$}
		\State $distance \gets distance + |p_{i} - q_{i}|$
	\EndFor
	\State \RETURN $distance$
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{Quicksort}\label{alg:qsort}
\begin{algorithmic}[1]
\Procedure{Quicksort}{$index,distance,low,high$}
	\If{$low<high$}
		\State $pivot \gets$ Partition($index,distance,low,high$)
		\State Quicksort($index,dist,low,pivot-1$)
		\State Quicksort($index,dist,pivot+1,high$)
	\EndIf
\EndProcedure
\Procedure{Partition}{$index,distance,low,high$}
	\State $pivot \gets distance[high]$
	\State $i \gets low - 1$
	\For{$j\in [low,low+1,...,high-1,high]$}
		\If{$distance[j]\leq pivot$}
			\State $i \gets i + 1$
			\State Swap($distance[i],distance[j]$)
			\State Swap($index[i],index[j]$)
		\EndIf
	\EndFor
	\State Swap($distance[i+1],distance[high]$)
	\State Swap($index[i+1],index[high]$)
	\State \RETURN $i+1$
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{Bubblesort}\label{alg:bubblesort}
\begin{algorithmic}[1]
\Procedure{Bubblesort}{$index, distance $}
	\For{$i \in [0,...,m-1]$}
		\For{$j \in [0,...,m-i-1]$}
			\If{$distance[j]>distance[j+1]$}
				\State Swap($distance[j],distance[j+1]$)
				\State Swap($index[j],index[j+1]$)
			\EndIf
		\EndFor
	\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{Mergesort}\label{alg:mergesort}
\begin{algorithmic}[1]
\Procedure{MergesortParent}{$index, distance $}
	\State Create($index2$)
	\State Create($distance2$)
	\State Mergesort($index,index2,distance,distance2,0,m$)
	\State Destroy($index2$)
	\State Destroy($distance2$)
\EndProcedure
\Procedure{Mergesort}{$index,index2,distance,distance2,low,high$}
	\If{$low<high$}
		\State $mid \gets \frac{low+high}{2}$
		\State Mergesort($index,index2,distance,distance2,low,mid$)
		\State Mergesort($index,index2,distance,distance2,mid+1,high$)
		\State Merge($index,index2,distance,distance2,low,mid,high$)
	\EndIf
\EndProcedure
\Procedure{Merge}{$index,index2,distance,distance2,low,mid,high$}
	\State $l1 \gets low$
	\State $l2 \gets mid+1$
	\For{$i\gets low$;$l1\leq mid$\AND$l2\leq high$;$i\gets i+1$}
		\If{$distance[l1]\leq distance[l2]$}
			\State $distance2[i] \gets distance[l1]$
			\State $index2[i] \gets index[l1]$
			\State $l1 \gets l1 + 1$
		\Else
			\State $distance2[i] \gets distance[l2]$
			\State $index2[i] \gets index[l2]$
			\State $l2 \gets l2 + 1$
		\EndIf
	\EndFor
	\While{$l1\leq mid$}
		\State $distance2[i] \gets distance[l1]$
		\State $index2[i] \gets index[l1]$
		\State $l1 \gets l1 + 1$
		\State $i \gets i + 1$
	\EndWhile
	\While{$l2\leq high$}
		\State $distance2[i] \gets distance[l2]$
		\State $index2[i] \gets index[l2]$
		\State $l2 \gets l2 + 1$
		\State $i \gets i + 1$
	\EndWhile
	\State $distance \gets distance2$
	\State $index \gets index2$ 
\EndProcedure
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{Odd-Even Sort}\label{alg:oddeven}
\begin{algorithmic}[1]
\Procedure{OddEven}{$index, distance $}
	\For{$i \in [0,...,m-1]$}
		\State $j0 \gets i \% 2$
		\For{$j \in [j0,j0+2,...,m-1]$}
			\If{$distance[j]>distance[j+1]$}
				\State Swap($distance[j],distance[j+1]$)
				\State Swap($index[j],index[j+1]$)
			\EndIf
		\EndFor
	\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{document} 

